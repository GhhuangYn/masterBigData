collectagent.sources = r1
collectagent.channels = c1 c2
collectagent.sinks = k1 k2
#定义source
collectagent.sources.r1.type = avro
collectagent.sources.r1.bind = 192.168.183.100
collectagent.sources.r1.port = 8888
#设置interceptor拦截器
collectagent.sources.r1.interceptors = i1
collectagent.sources.r1.interceptors.i1.type = timestamp
collectagent.sources.r1.interceptors.i1.preserveExisting = false
#设置复制选择器
collectagent.sources.r1.selector.type = replicating
#设置required channel
collectagent.sources.r1.channels = c1 c2
#设置channel c1
collectagent.channels.c1.type = memory 
collectagent.channels.c1.capacity = 10000
collectagent.channels.c1.transactionCapacity = 1000
#设置channel c2
collectagent.channels.c2.type = memory
collectagent.channels.c2.capacity = 10000
collectagent.channels.c2.transactionCapacity = 1000
#设置kafka sink
collectagent.sinks.k1.channel = c1
collectagent.sinks.k1.type = org.apache.flume.sink.kafka.KafkaSink
collectagent.sinks.k1.kafka.topic = userlog1
collectagent.sinks.k1.kafka.bootstrap.servers = 192.168.183.102:9092,192.168.183.103:9092
collectagent.sinks.k1.kafka.flumeBatchSize = 5
collectagent.sinks.k1.kafka.producer.acks = 1
#设置hdfs sink
collectagent.sinks.k2.type = hdfs
collectagent.sinks.k2.channel = c2
collectagent.sinks.k2.hdfs.path = /data/userlog/dt=%Y%m%d
collectagent.sinks.k2.hdfs.filePrefix = userlog
collectagent.sinks.k2.hdfs.fileType = DataStream
collectagent.sinks.k2.hdfs.writeFormat = Text
collectagent.sinks.k2.hdfs.round = true
collectagent.sinks.k2.hdfs.roundValue = 10
collectagent.sinks.k2.hdfs.roundUnit = minute
collectagent.sinks.k2.hdfs.callTimeout = 60000
